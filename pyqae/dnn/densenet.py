import keras.backend as K
from keras.layers import Input, concatenate, ZeroPadding2D
from keras.layers.convolutional import Convolution2D
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.normalization import BatchNormalization
from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, \
    MaxPooling2D
from keras.models import Model

from pyqae.dnn.std_layers import Scale


def DenseNet(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0,
             dropout_rate=0.0, weight_decay=1e-4, classes=1000,
             suffix='', weights_path=None, input_shape=None):
    '''Instantiate the DenseNet 121 architecture,
        # Arguments
            nb_dense_block: number of dense blocks to add to end
            growth_rate: number of filters to add per dense block
            nb_filter: initial number of filters
            reduction: reduction factor of transition blocks.
            dropout_rate: dropout rate
            weight_decay: weight decay factor
            classes: optional number of classes to classify images
            weights_path: path to pre-trained weights
        # Returns
            A Keras model instance.
    >>> import numpy as np
    >>> mn = DenseNet()
    >>> len(mn.layers)
    609
    >>> mn.count_params()
    14181864
    >>> med_dense = DenseNet(input_shape = (64, 64, 1), classes = 2)
    >>> med_dense.predict(np.zeros((1, 64, 64, 1))).shape
    (1, 2)
    >>> med_simple = DenseNet(input_shape = (64, 64, 1), classes = 2, nb_dense_block = 2)
    >>> med_simple.summary()
    ____________________________________________________________________________________________________
    Layer (type)                     Output Shape          Param #     Connected to
    ====================================================================================================
    data (InputLayer)                (None, 64, 64, 1)     0
    ____________________________________________________________________________________________________
    conv1_zeropadding (ZeroPadding2D (None, 70, 70, 1)     0           data[0][0]
    ____________________________________________________________________________________________________
    conv1 (Conv2D)                   (None, 32, 32, 64)    3136        conv1_zeropadding[0][0]
    ____________________________________________________________________________________________________
    conv1_bn (BatchNormalization)    (None, 32, 32, 64)    256         conv1[0][0]
    ____________________________________________________________________________________________________
    conv1_scale (Scale)              (None, 32, 32, 64)    128         conv1_bn[0][0]
    ____________________________________________________________________________________________________
    relu1 (Activation)               (None, 32, 32, 64)    0           conv1_scale[0][0]
    ____________________________________________________________________________________________________
    pool1_zeropadding (ZeroPadding2D (None, 34, 34, 64)    0           relu1[0][0]
    ____________________________________________________________________________________________________
    pool1 (MaxPooling2D)             (None, 16, 16, 64)    0           pool1_zeropadding[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x1_bn (BatchNormalizatio (None, 16, 16, 64)    256         pool1[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x1_scale (Scale)         (None, 16, 16, 64)    128         conv2_1_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_1_x1 (Activation)          (None, 16, 16, 64)    0           conv2_1_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x1 (Conv2D)              (None, 16, 16, 128)   8192        relu2_1_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x2_bn (BatchNormalizatio (None, 16, 16, 128)   512         conv2_1_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x2_scale (Scale)         (None, 16, 16, 128)   256         conv2_1_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_1_x2 (Activation)          (None, 16, 16, 128)   0           conv2_1_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x2_zeropadding (ZeroPadd (None, 18, 18, 128)   0           relu2_1_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_1_x2 (Conv2D)              (None, 16, 16, 32)    36864       conv2_1_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_2_1 (Concatenate)         (None, 16, 16, 96)    0           pool1[0][0]
                                                                       conv2_1_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x1_bn (BatchNormalizatio (None, 16, 16, 96)    384         concat_2_1[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x1_scale (Scale)         (None, 16, 16, 96)    192         conv2_2_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_2_x1 (Activation)          (None, 16, 16, 96)    0           conv2_2_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x1 (Conv2D)              (None, 16, 16, 128)   12288       relu2_2_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x2_bn (BatchNormalizatio (None, 16, 16, 128)   512         conv2_2_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x2_scale (Scale)         (None, 16, 16, 128)   256         conv2_2_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_2_x2 (Activation)          (None, 16, 16, 128)   0           conv2_2_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x2_zeropadding (ZeroPadd (None, 18, 18, 128)   0           relu2_2_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_2_x2 (Conv2D)              (None, 16, 16, 32)    36864       conv2_2_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_2_2 (Concatenate)         (None, 16, 16, 128)   0           concat_2_1[0][0]
                                                                       conv2_2_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x1_bn (BatchNormalizatio (None, 16, 16, 128)   512         concat_2_2[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x1_scale (Scale)         (None, 16, 16, 128)   256         conv2_3_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_3_x1 (Activation)          (None, 16, 16, 128)   0           conv2_3_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x1 (Conv2D)              (None, 16, 16, 128)   16384       relu2_3_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x2_bn (BatchNormalizatio (None, 16, 16, 128)   512         conv2_3_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x2_scale (Scale)         (None, 16, 16, 128)   256         conv2_3_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_3_x2 (Activation)          (None, 16, 16, 128)   0           conv2_3_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x2_zeropadding (ZeroPadd (None, 18, 18, 128)   0           relu2_3_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_3_x2 (Conv2D)              (None, 16, 16, 32)    36864       conv2_3_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_2_3 (Concatenate)         (None, 16, 16, 160)   0           concat_2_2[0][0]
                                                                       conv2_3_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x1_bn (BatchNormalizatio (None, 16, 16, 160)   640         concat_2_3[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x1_scale (Scale)         (None, 16, 16, 160)   320         conv2_4_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_4_x1 (Activation)          (None, 16, 16, 160)   0           conv2_4_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x1 (Conv2D)              (None, 16, 16, 128)   20480       relu2_4_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x2_bn (BatchNormalizatio (None, 16, 16, 128)   512         conv2_4_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x2_scale (Scale)         (None, 16, 16, 128)   256         conv2_4_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_4_x2 (Activation)          (None, 16, 16, 128)   0           conv2_4_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x2_zeropadding (ZeroPadd (None, 18, 18, 128)   0           relu2_4_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_4_x2 (Conv2D)              (None, 16, 16, 32)    36864       conv2_4_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_2_4 (Concatenate)         (None, 16, 16, 192)   0           concat_2_3[0][0]
                                                                       conv2_4_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x1_bn (BatchNormalizatio (None, 16, 16, 192)   768         concat_2_4[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x1_scale (Scale)         (None, 16, 16, 192)   384         conv2_5_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_5_x1 (Activation)          (None, 16, 16, 192)   0           conv2_5_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x1 (Conv2D)              (None, 16, 16, 128)   24576       relu2_5_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x2_bn (BatchNormalizatio (None, 16, 16, 128)   512         conv2_5_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x2_scale (Scale)         (None, 16, 16, 128)   256         conv2_5_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_5_x2 (Activation)          (None, 16, 16, 128)   0           conv2_5_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x2_zeropadding (ZeroPadd (None, 18, 18, 128)   0           relu2_5_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_5_x2 (Conv2D)              (None, 16, 16, 32)    36864       conv2_5_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_2_5 (Concatenate)         (None, 16, 16, 224)   0           concat_2_4[0][0]
                                                                       conv2_5_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x1_bn (BatchNormalizatio (None, 16, 16, 224)   896         concat_2_5[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x1_scale (Scale)         (None, 16, 16, 224)   448         conv2_6_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_6_x1 (Activation)          (None, 16, 16, 224)   0           conv2_6_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x1 (Conv2D)              (None, 16, 16, 128)   28672       relu2_6_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x2_bn (BatchNormalizatio (None, 16, 16, 128)   512         conv2_6_x1[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x2_scale (Scale)         (None, 16, 16, 128)   256         conv2_6_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_6_x2 (Activation)          (None, 16, 16, 128)   0           conv2_6_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x2_zeropadding (ZeroPadd (None, 18, 18, 128)   0           relu2_6_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_6_x2 (Conv2D)              (None, 16, 16, 32)    36864       conv2_6_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_2_6 (Concatenate)         (None, 16, 16, 256)   0           concat_2_5[0][0]
                                                                       conv2_6_x2[0][0]
    ____________________________________________________________________________________________________
    conv2_blk_bn (BatchNormalization (None, 16, 16, 256)   1024        concat_2_6[0][0]
    ____________________________________________________________________________________________________
    conv2_blk_scale (Scale)          (None, 16, 16, 256)   512         conv2_blk_bn[0][0]
    ____________________________________________________________________________________________________
    relu2_blk (Activation)           (None, 16, 16, 256)   0           conv2_blk_scale[0][0]
    ____________________________________________________________________________________________________
    conv2_blk (Conv2D)               (None, 16, 16, 256)   65536       relu2_blk[0][0]
    ____________________________________________________________________________________________________
    pool2 (AveragePooling2D)         (None, 8, 8, 256)     0           conv2_blk[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x1_bn (BatchNormalizatio (None, 8, 8, 256)     1024        pool2[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x1_scale (Scale)         (None, 8, 8, 256)     512         conv3_1_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_1_x1 (Activation)          (None, 8, 8, 256)     0           conv3_1_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x1 (Conv2D)              (None, 8, 8, 128)     32768       relu3_1_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_1_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_1_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_1_x2 (Activation)          (None, 8, 8, 128)     0           conv3_1_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_1_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_1_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_1_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_1 (Concatenate)         (None, 8, 8, 288)     0           pool2[0][0]
                                                                       conv3_1_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x1_bn (BatchNormalizatio (None, 8, 8, 288)     1152        concat_3_1[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x1_scale (Scale)         (None, 8, 8, 288)     576         conv3_2_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_2_x1 (Activation)          (None, 8, 8, 288)     0           conv3_2_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x1 (Conv2D)              (None, 8, 8, 128)     36864       relu3_2_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_2_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_2_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_2_x2 (Activation)          (None, 8, 8, 128)     0           conv3_2_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_2_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_2_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_2_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_2 (Concatenate)         (None, 8, 8, 320)     0           concat_3_1[0][0]
                                                                       conv3_2_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x1_bn (BatchNormalizatio (None, 8, 8, 320)     1280        concat_3_2[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x1_scale (Scale)         (None, 8, 8, 320)     640         conv3_3_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_3_x1 (Activation)          (None, 8, 8, 320)     0           conv3_3_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x1 (Conv2D)              (None, 8, 8, 128)     40960       relu3_3_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_3_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_3_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_3_x2 (Activation)          (None, 8, 8, 128)     0           conv3_3_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_3_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_3_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_3_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_3 (Concatenate)         (None, 8, 8, 352)     0           concat_3_2[0][0]
                                                                       conv3_3_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x1_bn (BatchNormalizatio (None, 8, 8, 352)     1408        concat_3_3[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x1_scale (Scale)         (None, 8, 8, 352)     704         conv3_4_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_4_x1 (Activation)          (None, 8, 8, 352)     0           conv3_4_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x1 (Conv2D)              (None, 8, 8, 128)     45056       relu3_4_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_4_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_4_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_4_x2 (Activation)          (None, 8, 8, 128)     0           conv3_4_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_4_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_4_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_4_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_4 (Concatenate)         (None, 8, 8, 384)     0           concat_3_3[0][0]
                                                                       conv3_4_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x1_bn (BatchNormalizatio (None, 8, 8, 384)     1536        concat_3_4[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x1_scale (Scale)         (None, 8, 8, 384)     768         conv3_5_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_5_x1 (Activation)          (None, 8, 8, 384)     0           conv3_5_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x1 (Conv2D)              (None, 8, 8, 128)     49152       relu3_5_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_5_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_5_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_5_x2 (Activation)          (None, 8, 8, 128)     0           conv3_5_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_5_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_5_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_5_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_5 (Concatenate)         (None, 8, 8, 416)     0           concat_3_4[0][0]
                                                                       conv3_5_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x1_bn (BatchNormalizatio (None, 8, 8, 416)     1664        concat_3_5[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x1_scale (Scale)         (None, 8, 8, 416)     832         conv3_6_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_6_x1 (Activation)          (None, 8, 8, 416)     0           conv3_6_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x1 (Conv2D)              (None, 8, 8, 128)     53248       relu3_6_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_6_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_6_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_6_x2 (Activation)          (None, 8, 8, 128)     0           conv3_6_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_6_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_6_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_6_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_6 (Concatenate)         (None, 8, 8, 448)     0           concat_3_5[0][0]
                                                                       conv3_6_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x1_bn (BatchNormalizatio (None, 8, 8, 448)     1792        concat_3_6[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x1_scale (Scale)         (None, 8, 8, 448)     896         conv3_7_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_7_x1 (Activation)          (None, 8, 8, 448)     0           conv3_7_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x1 (Conv2D)              (None, 8, 8, 128)     57344       relu3_7_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_7_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_7_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_7_x2 (Activation)          (None, 8, 8, 128)     0           conv3_7_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_7_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_7_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_7_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_7 (Concatenate)         (None, 8, 8, 480)     0           concat_3_6[0][0]
                                                                       conv3_7_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x1_bn (BatchNormalizatio (None, 8, 8, 480)     1920        concat_3_7[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x1_scale (Scale)         (None, 8, 8, 480)     960         conv3_8_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_8_x1 (Activation)          (None, 8, 8, 480)     0           conv3_8_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x1 (Conv2D)              (None, 8, 8, 128)     61440       relu3_8_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_8_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_8_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_8_x2 (Activation)          (None, 8, 8, 128)     0           conv3_8_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_8_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_8_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_8_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_8 (Concatenate)         (None, 8, 8, 512)     0           concat_3_7[0][0]
                                                                       conv3_8_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x1_bn (BatchNormalizatio (None, 8, 8, 512)     2048        concat_3_8[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x1_scale (Scale)         (None, 8, 8, 512)     1024        conv3_9_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_9_x1 (Activation)          (None, 8, 8, 512)     0           conv3_9_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x1 (Conv2D)              (None, 8, 8, 128)     65536       relu3_9_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x2_bn (BatchNormalizatio (None, 8, 8, 128)     512         conv3_9_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x2_scale (Scale)         (None, 8, 8, 128)     256         conv3_9_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_9_x2 (Activation)          (None, 8, 8, 128)     0           conv3_9_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x2_zeropadding (ZeroPadd (None, 10, 10, 128)   0           relu3_9_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_9_x2 (Conv2D)              (None, 8, 8, 32)      36864       conv3_9_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_9 (Concatenate)         (None, 8, 8, 544)     0           concat_3_8[0][0]
                                                                       conv3_9_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x1_bn (BatchNormalizati (None, 8, 8, 544)     2176        concat_3_9[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x1_scale (Scale)        (None, 8, 8, 544)     1088        conv3_10_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_10_x1 (Activation)         (None, 8, 8, 544)     0           conv3_10_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x1 (Conv2D)             (None, 8, 8, 128)     69632       relu3_10_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_10_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_10_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_10_x2 (Activation)         (None, 8, 8, 128)     0           conv3_10_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_10_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_10_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_10_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_10 (Concatenate)        (None, 8, 8, 576)     0           concat_3_9[0][0]
                                                                       conv3_10_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x1_bn (BatchNormalizati (None, 8, 8, 576)     2304        concat_3_10[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x1_scale (Scale)        (None, 8, 8, 576)     1152        conv3_11_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_11_x1 (Activation)         (None, 8, 8, 576)     0           conv3_11_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x1 (Conv2D)             (None, 8, 8, 128)     73728       relu3_11_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_11_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_11_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_11_x2 (Activation)         (None, 8, 8, 128)     0           conv3_11_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_11_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_11_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_11_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_11 (Concatenate)        (None, 8, 8, 608)     0           concat_3_10[0][0]
                                                                       conv3_11_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x1_bn (BatchNormalizati (None, 8, 8, 608)     2432        concat_3_11[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x1_scale (Scale)        (None, 8, 8, 608)     1216        conv3_12_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_12_x1 (Activation)         (None, 8, 8, 608)     0           conv3_12_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x1 (Conv2D)             (None, 8, 8, 128)     77824       relu3_12_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_12_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_12_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_12_x2 (Activation)         (None, 8, 8, 128)     0           conv3_12_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_12_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_12_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_12_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_12 (Concatenate)        (None, 8, 8, 640)     0           concat_3_11[0][0]
                                                                       conv3_12_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x1_bn (BatchNormalizati (None, 8, 8, 640)     2560        concat_3_12[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x1_scale (Scale)        (None, 8, 8, 640)     1280        conv3_13_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_13_x1 (Activation)         (None, 8, 8, 640)     0           conv3_13_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x1 (Conv2D)             (None, 8, 8, 128)     81920       relu3_13_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_13_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_13_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_13_x2 (Activation)         (None, 8, 8, 128)     0           conv3_13_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_13_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_13_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_13_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_13 (Concatenate)        (None, 8, 8, 672)     0           concat_3_12[0][0]
                                                                       conv3_13_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x1_bn (BatchNormalizati (None, 8, 8, 672)     2688        concat_3_13[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x1_scale (Scale)        (None, 8, 8, 672)     1344        conv3_14_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_14_x1 (Activation)         (None, 8, 8, 672)     0           conv3_14_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x1 (Conv2D)             (None, 8, 8, 128)     86016       relu3_14_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_14_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_14_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_14_x2 (Activation)         (None, 8, 8, 128)     0           conv3_14_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_14_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_14_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_14_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_14 (Concatenate)        (None, 8, 8, 704)     0           concat_3_13[0][0]
                                                                       conv3_14_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x1_bn (BatchNormalizati (None, 8, 8, 704)     2816        concat_3_14[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x1_scale (Scale)        (None, 8, 8, 704)     1408        conv3_15_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_15_x1 (Activation)         (None, 8, 8, 704)     0           conv3_15_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x1 (Conv2D)             (None, 8, 8, 128)     90112       relu3_15_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_15_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_15_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_15_x2 (Activation)         (None, 8, 8, 128)     0           conv3_15_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_15_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_15_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_15_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_15 (Concatenate)        (None, 8, 8, 736)     0           concat_3_14[0][0]
                                                                       conv3_15_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x1_bn (BatchNormalizati (None, 8, 8, 736)     2944        concat_3_15[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x1_scale (Scale)        (None, 8, 8, 736)     1472        conv3_16_x1_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_16_x1 (Activation)         (None, 8, 8, 736)     0           conv3_16_x1_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x1 (Conv2D)             (None, 8, 8, 128)     94208       relu3_16_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x2_bn (BatchNormalizati (None, 8, 8, 128)     512         conv3_16_x1[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x2_scale (Scale)        (None, 8, 8, 128)     256         conv3_16_x2_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_16_x2 (Activation)         (None, 8, 8, 128)     0           conv3_16_x2_scale[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x2_zeropadding (ZeroPad (None, 10, 10, 128)   0           relu3_16_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_16_x2 (Conv2D)             (None, 8, 8, 32)      36864       conv3_16_x2_zeropadding[0][0]
    ____________________________________________________________________________________________________
    concat_3_16 (Concatenate)        (None, 8, 8, 768)     0           concat_3_15[0][0]
                                                                       conv3_16_x2[0][0]
    ____________________________________________________________________________________________________
    conv3_blk_bn (BatchNormalization (None, 8, 8, 768)     3072        concat_3_16[0][0]
    ____________________________________________________________________________________________________
    conv3_blk_scale (Scale)          (None, 8, 8, 768)     1536        conv3_blk_bn[0][0]
    ____________________________________________________________________________________________________
    relu3_blk (Activation)           (None, 8, 8, 768)     0           conv3_blk_scale[0][0]
    ____________________________________________________________________________________________________
    pool3 (GlobalAveragePooling2D)   (None, 768)           0           relu3_blk[0][0]
    ____________________________________________________________________________________________________
    fc6 (Dense)                      (None, 2)             1538        pool3[0][0]
    ____________________________________________________________________________________________________
    prob (Activation)                (None, 2)             0           fc6[0][0]
    ====================================================================================================
    Total params: 2,083,842
    Trainable params: 2,058,434
    Non-trainable params: 25,408
    ____________________________________________________________________________________________________
    >>> med_dense.count_params()
    12258434
    '''
    eps = 1.1e-5

    # compute compression factor
    compression = 1.0 - reduction

    # Handle Dimension Ordering for different backends
    global concat_axis
    if K.image_dim_ordering() == 'tf':
        concat_axis = 3
        img_input = Input(
            shape=(224, 224, 3) if input_shape is None else input_shape,
            name='data{}'.format(suffix))
    else:
        concat_axis = 1
        img_input = Input(shape=(3, 224, 224) if input_shape is None else
        input_shape, name='data{}'.format(suffix))

    # From architecture for ImageNet (Table 1 in the paper)
    nb_filter = 64
    nb_layers = [6, 12, 24, 16]  # For DenseNet-121

    # Initial convolution
    x = ZeroPadding2D((3, 3), name='conv1_zeropadding{}'.format(suffix))(
        img_input)
    x = Convolution2D(nb_filter, 7, 7,
                      subsample=(2, 2),
                      name='conv1{}'.format(suffix),
                      use_bias=False)(x)
    x = BatchNormalization(epsilon=eps,
                           axis=concat_axis,
                           name='conv1_bn{}'.format(suffix))(x)
    x = Scale(axis=concat_axis, name='conv1_scale{}'.format(suffix))(x)
    x = Activation('relu', name='relu1{}'.format(suffix))(x)
    x = ZeroPadding2D((1, 1), name='pool1_zeropadding{}'.format(suffix))(x)
    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1{}'.format(suffix))(x)

    # Add dense blocks
    for block_idx in range(nb_dense_block - 1):
        stage = block_idx + 2
        x, nb_filter = dense_block(x, stage, nb_layers[block_idx],
                                   nb_filter, growth_rate,
                                   dropout_rate=dropout_rate,
                                   weight_decay=weight_decay, suffix=suffix)

        # Add transition_block
        x = transition_block(x, stage, nb_filter, compression=compression,
                             dropout_rate=dropout_rate,
                             weight_decay=weight_decay, suffix=suffix)
        nb_filter = int(nb_filter * compression)

    final_stage = stage + 1
    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter,
                               growth_rate, dropout_rate=dropout_rate,
                               weight_decay=weight_decay, suffix=suffix)

    x = BatchNormalization(epsilon=eps,
                           axis=concat_axis,
                           name='conv{}_blk_bn{}'.format(final_stage,
                                                         suffix))(x)
    x = Scale(axis=concat_axis, name='conv{}_blk_scale{}'.format(final_stage,
                                                                 suffix))(x)
    x = Activation('relu', name='relu{}_blk{}'.format(final_stage,
                                                      suffix))(x)
    x = GlobalAveragePooling2D(name='pool{}{}'.format(final_stage,
                                                      suffix))(x)

    x = Dense(classes, name='fc6{}'.format(suffix))(x)
    x = Activation('softmax', name='prob{}'.format(suffix))(x)

    model = Model(img_input, x, name='densenet{}'.format(suffix))

    if weights_path is not None:
        model.load_weights(weights_path)

    return model


def conv_block(x, stage, branch, nb_filter, dropout_rate=None,
               weight_decay=1e-4, suffix=''):
    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout
        # Arguments
            x: input tensor
            stage: index for dense block
            branch: layer index within each dense block
            nb_filter: number of filters
            dropout_rate: dropout rate
            weight_decay: weight decay factor
    '''
    eps = 1.1e-5
    conv_name_base = 'conv' + str(stage) + '_' + str(branch) + suffix
    relu_name_base = 'relu' + str(stage) + '_' + str(branch) + suffix

    # 1x1 Convolution (Bottleneck layer)
    inter_channel = nb_filter * 4
    x = BatchNormalization(epsilon=eps, axis=concat_axis,
                           name=conv_name_base + '_x1_bn')(x)
    x = Scale(axis=concat_axis, name=conv_name_base + '_x1_scale')(x)
    x = Activation('relu', name=relu_name_base + '_x1')(x)
    x = Convolution2D(inter_channel, (1, 1), name=conv_name_base + '_x1',
                      use_bias=False)(x)

    if dropout_rate:
        x = Dropout(dropout_rate)(x)

    # 3x3 Convolution
    x = BatchNormalization(epsilon=eps, axis=concat_axis,
                           name=conv_name_base + '_x2_bn')(x)
    x = Scale(axis=concat_axis, name=conv_name_base + '_x2_scale')(x)
    x = Activation('relu', name=relu_name_base + '_x2')(x)
    x = ZeroPadding2D((1, 1), name=conv_name_base + '_x2_zeropadding')(x)
    x = Convolution2D(nb_filter, (3, 3), name=conv_name_base + '_x2',
                      use_bias=False)(x)

    if dropout_rate:
        x = Dropout(dropout_rate)(x)

    return x


def transition_block(x, stage, nb_filter, compression=1.0,
                     dropout_rate=None, weight_decay=1E-4, suffix=''):
    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout
        # Arguments
            x: input tensor
            stage: index for dense block
            nb_filter: number of filters
            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.
            dropout_rate: dropout rate
            weight_decay: weight decay factor
    '''

    eps = 1.1e-5
    conv_name_base = 'conv' + str(stage) + '_blk' + suffix
    relu_name_base = 'relu' + str(stage) + '_blk' + suffix
    pool_name_base = 'pool' + str(stage) + suffix

    x = BatchNormalization(epsilon=eps, axis=concat_axis,
                           name=conv_name_base + '_bn')(x)
    x = Scale(axis=concat_axis, name=conv_name_base + '_scale')(x)
    x = Activation('relu', name=relu_name_base)(x)
    x = Convolution2D(int(nb_filter * compression), (1, 1),
                      name=conv_name_base,
                      use_bias=False)(x)

    if dropout_rate:
        x = Dropout(dropout_rate)(x)

    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)

    return x


def dense_block(x, stage, nb_layers, nb_filter, growth_rate,
                dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True,
                suffix=''):
    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones
        # Arguments
            x: input tensor
            stage: index for dense block
            nb_layers: the number of layers of conv_block to append to the model.
            nb_filter: number of filters
            growth_rate: growth rate
            dropout_rate: dropout rate
            weight_decay: weight decay factor
            grow_nb_filters: flag to decide to allow number of filters to grow
    '''

    eps = 1.1e-5
    concat_feat = x

    for i in range(nb_layers):
        branch = i + 1
        x = conv_block(concat_feat, stage, branch, growth_rate,
                       dropout_rate, weight_decay, suffix=suffix)
        concat_feat = concatenate([concat_feat, x],
                                  axis=concat_axis, name='concat_' + str(
                stage) + '_' + str(branch) + suffix)

        if grow_nb_filters:
            nb_filter += growth_rate

    return concat_feat, nb_filter
